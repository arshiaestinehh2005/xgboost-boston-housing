\# ğŸ¡ XGBoost Regression on Boston Housing Dataset



This project demonstrates the use of \*\*XGBoost\*\*, a powerful gradient boosting algorithm, to perform \*\*regression analysis\*\* on the famous \*\*Boston Housing dataset\*\*. The goal is to predict housing prices based on various features such as crime rate, number of rooms, and accessibility to highways.



## ğŸ“Œ Project Objectives



- Perform data preprocessing and cleaning.

- Train an XGBoost Regressor model.

- Evaluate the model using metrics such as RÂ², MAE, MSE, and RMSE.

- Visualize feature importances to understand the most impactful variables.



## ğŸš€ Technologies Used



- Python 3.10+

- Jupyter Notebook

- pandas

- numpy

- matplotlib

- seaborn

- scikit-learn

- xgboost



## ğŸ“Š Model Performance



- \*\*RÂ² Score:\*\* 0.92 (example)

- \*\*MAE:\*\* ~2.4

- \*\*RMSE:\*\* ~3.1



> The model demonstrates high predictive performance, indicating that XGBoost is well-suited for structured tabular regression tasks.





## ğŸ“ˆ Visualizations



- Correlation heatmap

- Feature importance plot

- Actual vs Predicted price plot



ğŸ§ª Evaluation Metrics

Metric	Description

RÂ² Score	Measures how well the predictions approximate the actual data.

MAE	Mean Absolute Error - average magnitude of errors.

MSE	Mean Squared Error - penalizes larger errors.

RMSE	Root Mean Squared Error - square root of MSE, interpretable in original units.



Example results (you can update them with your actual results):



RÂ² Score: 0.92



MAE: ~2.4



RMSE: ~3.1



MSE:	Mean Squared Error - penalizes larger errors 







âœï¸ Author

Arshia Estineh

Machine Learning Developer | France ğŸ‡«ğŸ‡·

arshiaestineh2005@icloud.com



