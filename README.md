\# 🏡 XGBoost Regression on Boston Housing Dataset



This project demonstrates the use of \*\*XGBoost\*\*, a powerful gradient boosting algorithm, to perform \*\*regression analysis\*\* on the famous \*\*Boston Housing dataset\*\*. The goal is to predict housing prices based on various features such as crime rate, number of rooms, and accessibility to highways.



## 📌 Project Objectives



- Perform data preprocessing and cleaning.

- Train an XGBoost Regressor model.

- Evaluate the model using metrics such as R², MAE, MSE, and RMSE.

- Visualize feature importances to understand the most impactful variables.



## 🚀 Technologies Used



- Python 3.10+

- Jupyter Notebook

- pandas

- numpy

- matplotlib

- seaborn

- scikit-learn

- xgboost



## 📊 Model Performance



- \*\*R² Score:\*\* 0.92 (example)

- \*\*MAE:\*\* ~2.4

- \*\*RMSE:\*\* ~3.1



> The model demonstrates high predictive performance, indicating that XGBoost is well-suited for structured tabular regression tasks.





## 📈 Visualizations



- Correlation heatmap

- Feature importance plot

- Actual vs Predicted price plot



🧪 Evaluation Metrics

Metric	Description

R² Score	Measures how well the predictions approximate the actual data.

MAE	Mean Absolute Error - average magnitude of errors.

MSE	Mean Squared Error - penalizes larger errors.

RMSE	Root Mean Squared Error - square root of MSE, interpretable in original units.



Example results (you can update them with your actual results):



R² Score: 0.92



MAE: ~2.4



RMSE: ~3.1



MSE:	Mean Squared Error - penalizes larger errors 







✍️ Author

Arshia Estineh

Machine Learning Developer | France 🇫🇷

arshiaestineh2005@icloud.com



